{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ebbae7b-fdc0-455c-94e1-be9565e06684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk==3.5\n",
      "  Using cached nltk-3.5-py3-none-any.whl\n",
      "Requirement already satisfied: click in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from nltk==3.5) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from nltk==3.5) (1.4.0)\n",
      "Requirement already satisfied: regex in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from nltk==3.5) (2024.4.16)\n",
      "Requirement already satisfied: tqdm in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from nltk==3.5) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from click->nltk==3.5) (0.4.6)\n",
      "Installing collected packages: nltk\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.8.1\n",
      "    Uninstalling nltk-3.8.1:\n",
      "      Successfully uninstalled nltk-3.8.1\n",
      "Successfully installed nltk-3.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "textblob 0.18.0.post0 requires nltk>=3.8, but you have nltk 3.5 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk==3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05bd80ef-5474-4971-80e9-d82a7aa93ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "555ae8ee-be7e-4383-8ed9-d7314625adc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from scikit-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from scikit-learn) (3.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "880568c2-4ad0-42ec-a34c-6150a1d0bc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (0.18.0.post0)\n",
      "Collecting nltk>=3.8 (from textblob)\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: click in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from nltk>=3.8->textblob) (1.4.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from nltk>=3.8->textblob) (2024.4.16)\n",
      "Requirement already satisfied: tqdm in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from nltk>=3.8->textblob) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from click->nltk>=3.8->textblob) (0.4.6)\n",
      "Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Installing collected packages: nltk\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.5\n",
      "    Uninstalling nltk-3.5:\n",
      "      Successfully uninstalled nltk-3.5\n",
      "Successfully installed nltk-3.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac4bd52c-7cc6-402e-bce0-049243c6d925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aliaa\\anaconda3\\envs\\nlp_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e06a8391-5f72-47d7-99e4-191a9a2fc3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aliaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\aliaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aliaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c6c9fce-c67a-47a1-87d1-dce61d085819",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from textblob import TextBlob\n",
    "from nltk.stem import PorterStemmer\n",
    "from textblob import Word\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "import sklearn.feature_extraction.text as text\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db47cb2e-70f0-4c51-a59f-fc0d8e3390b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ebb4bec-318d-42f6-93be-40b069f5dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "News_Data = pd.read_csv(\"news.csv\")\n",
    "#Encoding Latin1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd195845-41c2-48d3-8192-19507833e709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_only(text):\n",
    "    # Sentence tokenize the text\n",
    "    sentences = sent_tokenize(text)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a83d9e84-0c69-4bcd-86dd-3f82a36a515f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pre processing steps like lower case, stemming and lemmatization\n",
    "\n",
    "\n",
    "# News_Data['title'] = News_Data['title'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "# stop = stopwords.words('english')\n",
    "# News_Data['title'] = News_Data['title'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "# st = PorterStemmer()\n",
    "# # News_Data['title'] = News_Data['title'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
    "# News_Data['title'] =News_Data['title'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "\n",
    "#News_Data['text'] = News_Data['text'].apply(tokenize_only)\n",
    "News_Data['text'] = News_Data['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "stop = stopwords.words('english')\n",
    "News_Data['text'] = News_Data['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "st = PorterStemmer()\n",
    "# News_Data['title'] = News_Data['title'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
    "News_Data['text'] =News_Data['text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45be3447-ab05-41bc-a1cc-69d5c328cdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       daniel greenfield, shillman journalism fellow ...\n",
      "1       google pinterest digg linkedin reddit stumbleu...\n",
      "2       u.s. secretary state john f. kerry said monday...\n",
      "3       — kaydee king (@kaydeeking) november 9, 2016 l...\n",
      "4       primary day new york front-runner hillary clin...\n",
      "                              ...                        \n",
      "6330    state department told republican national comm...\n",
      "6331    ‘p’ pb stand ‘plutocratic’ ‘pentagon’ posted o...\n",
      "6332    anti-trump protester tool oligarchy reform al...\n",
      "6333    addis ababa, ethiopia —president obama convene...\n",
      "6334    jeb bush suddenly attacking trump. here's matt...\n",
      "Name: text, Length: 6335, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(News_Data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c3beb94-4bbf-40d1-a023-dfefbafe1b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cedar rapids, iowa — “i one wonderful rally entire career right 1992,” bill clinton said way opening crowd 1,100 saturday night. two day iowa caucuses, cedar rapid tried deliver old feeling wife, hillary clinton. crowd, one woman held sign said “227 year men. it’s turn!\" carried sign books. others traveled far missouri. waited hours, even fire marshal told room inside high school gymnasium. restive crowd chanted slogan buzzed anticipation finally bill, hillary chelsea clinton appeared stage hand-in-hand, hour behind schedule. roared, hillary clinton beamed. long slog iowa clinton campaign, struggled mightily shake label supporter can’t muster enthusiasm rival’s backers. caucus near, help former president, energy level event notably dialing up. \"he's charismatic speaker,\" said cigi ross, 31. \"in general, i'd say he's bigger draw people.\" monday night put campaign's month work test. campaign’s organization bring supporters? candidate energize voters? clinton, seemed draw higher-than-usual energy, stood center delivered confident closing statement. “what need plan, commitment,” clinton said top voice. “and me, yes, thank you,” clinton finished. eight year later, clinton iowa facing could nail-biting conclusion hard-fought campaign. clinton acknowledges isn’t campaign changed since devastating loss last run, changed — improved, told cnn saturday. \"i think different, perhaps better, candidate, hope also shows,\" clinton said interview network morning. day ago, iowa seemed slipping grasp, campaign aide feeling confident now. slew positive news, endorsements, latest poll de moines register bloomberg news indicate bleeding least slowed. poll -- considered gold standard iowa -- gave clinton slim lead rival vermont sen. bernie sanders. democrat wary political dynasties, didn’t show it. spotting someone audience carrying chelsea clinton's book, father remarked: \"thank you, young woman, holding book.\" bill clinton, spent day crisscrossing state wife's behalf, settled easily role booster-in-chief. lay policy, leaving wife. focus instead know \"about job.\" “there certain, almost intangible quality determine whether president succeeds not,” clinton said, voice raspy, even low. \"you need sticker. sticker: someone won’t quit you.” \"she’s best i’ve ever known,” added.\n"
     ]
    }
   ],
   "source": [
    "print(News_Data['text'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1333cf6-8e11-49b8-937b-bab7cbd634d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>daniel greenfield, shillman journalism fellow ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>google pinterest digg linkedin reddit stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>u.s. secretary state john f. kerry said monday...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— kaydee king (@kaydeeking) november 9, 2016 l...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>primary day new york front-runner hillary clin...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  daniel greenfield, shillman journalism fellow ...  FAKE  \n",
       "1  google pinterest digg linkedin reddit stumbleu...  FAKE  \n",
       "2  u.s. secretary state john f. kerry said monday...  REAL  \n",
       "3  — kaydee king (@kaydeeking) november 9, 2016 l...  FAKE  \n",
       "4  primary day new york front-runner hillary clin...  REAL  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "News_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dcab975-8ea9-465f-84ed-a9b58c10284f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.38440324, 0.12968134, 0.4082744 , ..., 0.29581551, 0.34020509,\n",
       "       0.46451471])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=News_Data.iloc[:,1:3]\n",
    "Y=News_Data[\"label\"]\n",
    "#print(X[\"title\"])\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(X[\"title\"],Y)\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)\n",
    "\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "tfidf_vect.fit(X[\"title\"])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x)\n",
    "\n",
    "xtrain_tfidf.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42bd727b-53f8-4a7d-a54d-24f405b70dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42561927, 0.36994868, 0.31673838, ..., 0.03696162, 0.03597595,\n",
       "       0.02647125])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=News_Data.iloc[:,1:3]\n",
    "Y=News_Data[\"label\"]\n",
    "#print(X[\"title\"])\n",
    "\n",
    "train_x_2, valid_x_2, train_y_2, valid_y_2 = model_selection.train_test_split(X[\"text\"],Y)\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y_2 = encoder.fit_transform(train_y_2)\n",
    "valid_y_2= encoder.fit_transform(valid_y_2)\n",
    "\n",
    "tfidf_vect_2 = TfidfVectorizer()\n",
    "tfidf_vect_2.fit(X[\"title\"])\n",
    "xtrain_tfidf_2 =  tfidf_vect.transform(train_x_2)\n",
    "xvalid_tfidf_2 =  tfidf_vect.transform(valid_x_2)\n",
    "\n",
    "xtrain_tfidf_2.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56e38bc2-0752-4725-a9af-b07f8bd7f2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    return metrics.accuracy_score(predictions, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84cff0a8-5b0d-48b7-9f3f-d9e63652e422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4753787878787879\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(PassiveAggressiveClassifier(C=10, random_state=42), xtrain_tfidf_2, train_y_2, xvalid_tfidf_2)\n",
    "print (\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9d96131-c82c-4dee-a55e-af7374f85de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.476010101010101\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_2, train_y_2, xvalid_tfidf_2)\n",
    "print (\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e24a4f0-78e0-4ba8-b794-2180f44f65d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4791666666666667\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes trainig\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(alpha=0.2), xtrain_tfidf_2, train_y_2, xvalid_tfidf_2)\n",
    "print (\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0554d613-7a62-46e0-8574-b5eece39ccec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5351f5e-e6a7-42bf-a9f4-b25ec83cb7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d102c22d-786f-4e35-b834-e0e7a67e889f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7646ef06-746e-4b86-a876-b5a3a02b0e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
