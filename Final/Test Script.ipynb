{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1a4b140-a679-4139-b8fe-1e27663ffb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from textblob import Word\n",
    "import gensim\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1abaae40-3437-44e6-9871-a6057cb36098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ranee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ranee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ranee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50b038ff-6e3d-480d-99dc-8dd9e359032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Data = pd.read_csv(\"D:\\\\Uni Related\\\\NLP\\\\Project\\\\news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d569c29-af18-4e72-a1ed-e580aa2eb1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('selected features.pkl', 'rb') as f:\n",
    "    encoder = pickle.load(f)\n",
    "    tfidf_vect = pickle.load(f)\n",
    "    count_vectorizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c7e9381-2b50-47e0-a4d7-e6d427a23ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scaling.pkl', 'rb')as f:\n",
    "    scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c142fd7-750a-427e-a09d-3976e2ee698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('selected models.pkl', 'rb') as f:\n",
    "    PassiveAggressive_TFIDF = pickle.load(f)\n",
    "    LogisticRegression_TFIDF = pickle.load(f)\n",
    "    NaiveBayesTFIDF = pickle.load(f)\n",
    "    PassiveAggressiveWord2Vec = pickle.load(f)\n",
    "    LogisticRegressionWord2Vec = pickle.load(f)\n",
    "    NaiveBayesWord2Vec = pickle.load(f)\n",
    "    PassiveAggressiveCountVectorizer = pickle.load(f)\n",
    "    LogisticRegressionCountVectorizer = pickle.load(f)\n",
    "    NaiveBayesCountVectorizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "122d3a09-1bd5-4a5e-b497-25c235eaebe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_only(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af16137e-e653-4abc-b6a1-d1948013fea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, Y_actual, model_name, vector_name):\n",
    "    predictions = classifier.predict(feature_vector_train)\n",
    "    test_accuracy = metrics.accuracy_score(predictions, Y_actual)\n",
    "    print(f\"Accuracy of {model_name} using {vector_name} : {test_accuracy}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d3c6525-e4db-457a-beef-8a210bc4e6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_vector(sentence, model):\n",
    "    vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d1b001d-218c-457c-af52-cc7ed8873eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsTextList = Test_Data['text'].apply(tokenize_only)\n",
    "\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebecfac0-22e6-4f78-b313-1248e801bcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Data['text'] = Test_Data['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "Test_Data['text'] = Test_Data['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "Test_Data['text'] = Test_Data['text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "\n",
    "Test_Data['title'] = Test_Data['title'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "Test_Data['title'] = Test_Data['title'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "Test_Data['title'] = Test_Data['title'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "\n",
    "X = Test_Data['text']\n",
    "Y = Test_Data[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5226f73b-a315-4799-a86e-08053d0a0d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_encoded = encoder.transform(Y)\n",
    "x_after_tfidf = tfidf_vect.transform(X)\n",
    "Word2Vec_model = Word2Vec(X)\n",
    "x_vector = [sentence_to_vector(sentence, Word2Vec_model) for sentence in X]\n",
    "X_count_vectorizer = count_vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c38ff325-d47d-4064-9df8-73afdbdd7f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of PassiveAggressiveClassifier using TF-IDF : 0.9854775059194949\n",
      "\n",
      "Accuracy of LogisticRegression using TF-IDF : 0.9480662983425414\n",
      "\n",
      "Accuracy of MultinomialNB using TF-IDF : 0.935438042620363\n",
      "\n",
      "Accuracy of PassiveAggressiveClassifier using Word2Vec : 0.4702446724546172\n",
      "\n",
      "Accuracy of LogisticRegression using Word2Vec : 0.4994475138121547\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_PassiveAggressiveClassifier_TFIDF = train_model(PassiveAggressive_TFIDF,\n",
    "                                                         x_after_tfidf, y_encoded, 'PassiveAggressiveClassifier',\n",
    "                                                         'TF-IDF')\n",
    "accuracy_LogisticRegression_TFIDF = train_model(LogisticRegression_TFIDF, x_after_tfidf,\n",
    "                                                y_encoded, 'LogisticRegression', 'TF-IDF')\n",
    "\n",
    "accuracy_MultinomialNB_TFIDF = train_model(NaiveBayesTFIDF, x_after_tfidf, y_encoded, 'MultinomialNB', 'TF-IDF')\n",
    "\n",
    "accuracy_PassiveAggressiveClassifier_Word2Vec = train_model(PassiveAggressiveWord2Vec,\n",
    "                                                            x_vector, y_encoded,\n",
    "                                                            'PassiveAggressiveClassifier', 'Word2Vec')\n",
    "\n",
    "accuracy_LogisticRegression_Word2Vec = train_model(LogisticRegressionWord2Vec, x_vector,\n",
    "                                                   y_encoded, 'LogisticRegression', 'Word2Vec')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cfc54ab-a9c5-4080-875f-f99ef7e5082f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of MultinomialNB using Word2Vec : 0.4994475138121547\n",
      "\n",
      "Accuracy of PassiveAggressiveClassifier using CountVectorizer : 0.9747434885556433\n",
      "\n",
      "Accuracy of LogisticRegression using CountVectorizer : 0.9797947908445146\n",
      "\n",
      "Accuracy of MultinomialNB using CountVectorizer : 0.9412786108918706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# scaling\n",
    "x_woerdtovec_scaled = scaler.transform(x_vector)\n",
    "\n",
    "accuracy_MultinomialNB_Word2Vec = train_model(NaiveBayesWord2Vec, x_woerdtovec_scaled,\n",
    "                                              y_encoded, 'MultinomialNB', 'Word2Vec')\n",
    "\n",
    "accuracy_PassiveAggressiveClassifier_CountVectorizer = train_model(PassiveAggressiveCountVectorizer,\n",
    "                                                                   X_count_vectorizer, y_encoded,\n",
    "                                                                   'PassiveAggressiveClassifier', 'CountVectorizer')\n",
    "\n",
    "accuracy_LogisticRegression_CountVectorizer = train_model(LogisticRegressionCountVectorizer, X_count_vectorizer,\n",
    "                                                          y_encoded,\n",
    "                                                          'LogisticRegression', 'CountVectorizer')\n",
    "\n",
    "accuracy_MultinomialNB_CountVectorizer = train_model(NaiveBayesCountVectorizer, X_count_vectorizer,\n",
    "                                                     y_encoded, 'MultinomialNB', 'CountVectorizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de1a404-127a-461a-a5cb-5d021ce789e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
